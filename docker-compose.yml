services:
  # -----------------------------
  # The Go Orchestrator (Proxy)
  # -----------------------------
  proxy:
    build:
      context: ./proxy
      dockerfile: Dockerfile
    container_name: baldr-proxy
    ports:
      - "8080:8080"
    environment:
      # OVERRIDE the code defaults here
      - SERVER_PORT=8080
      # Critical: Use the Docker Service Name ("guardrail"), not localhost
      - GUARDRAIL_URL=http://guardrail:8000/validate
      - LLM_URL=https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
      - LLM_API_KEY=${GEMINI_API_KEY}
      - GUARDRAIL_MAX_CONCURRENCY=50
    depends_on:
      - guardrail
    networks:
      - baldr-net

  # -----------------------------
  # The Python Sidecar (Guardrail)
  # -----------------------------
  guardrail:
    build:
      context: ./guardrail
      dockerfile: Dockerfile
    container_name: baldr-guardrail
    environment:
      # Control how slow the Python service is for stress testing
      - SIMULATED_LATENCY_MS=100
      - PYTHONUNBUFFERED="1"
    networks:
      - baldr-net

networks:
  baldr-net:
    driver: bridge
